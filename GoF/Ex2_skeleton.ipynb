{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbinned chi2 for Gaussian data\n",
    "def calc_chi2(yy,mean,sigma):\n",
    "    ... #TODO write here\n",
    "    return chi2val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myhist:\n",
    "    \"\"\"\n",
    "    A simple histogram class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, bins):\n",
    "        \"\"\"\n",
    "        Constructor with bins and data.\n",
    "        \n",
    "        Both are arrays, but the size of bins is that of data + 1,\n",
    "        because the former contains bin edges and the latter the bin contents.\n",
    "        \n",
    "        If no data are provided, generate some\n",
    "        \"\"\"\n",
    "        if len(bins) != len(data) + 1:\n",
    "            print(\"ERROR inconsistent sizes for bins and data\")\n",
    "            return\n",
    "        \n",
    "        self.bins = bins\n",
    "        self.data = data\n",
    "        # also store bin centers for convenience\n",
    "        self.binc = [(bins[i] + bins[i+1]) / 2 for i in range(len(data))]\n",
    "        # and the sum of the data\n",
    "        self.tot = sum(data)\n",
    "        \n",
    "    # define GoF functions\n",
    "    def PearsonChi2(self, model_cdf):\n",
    "        \"\"\"\n",
    "        Pearson chi2.\n",
    "        model_cdf is the cdf of the model\n",
    "        \"\"\"\n",
    "        nbins = len(self.data)\n",
    "        chi2val = 0\n",
    "        ndf = 0\n",
    "        for i in range(nbins):\n",
    "            # data\n",
    "            d = self.data[i]\n",
    "            \n",
    "            # model prediction in that bin:\n",
    "            # integral of the pdf in the bin, i.e. difference of the cdf at the bin edges\n",
    "            p = model_cdf(bins[i+1]) - model_cdf(bins[i])\n",
    "            \n",
    "            # implement chi2 here (careful with empty bins!)\n",
    "            chi2val = ... #TODO write here\n",
    "        \n",
    "        return chi2val, ndf\n",
    "    \n",
    "    def NeymanChi2(self, model_cdf):\n",
    "        \"\"\"\n",
    "        Pearson chi2.\n",
    "        model_cdf is the cdf of the model\n",
    "        \"\"\"\n",
    "        nbins = len(self.data)\n",
    "        chi2val = 0\n",
    "        ndf = 0\n",
    "        for i in range(nbins):\n",
    "            d = self.data[i]\n",
    "            \n",
    "            # model prediction in that bin:\n",
    "            # integral of the pdf in the bin, i.e. difference of the cdf at the bin edges\n",
    "            p = model_cdf(bins[i+1]) - model_cdf(bins[i])\n",
    "            \n",
    "            # implement chi2 here (careful with empty bins!)\n",
    "            chi2val = ... #TODO write here\n",
    "        \n",
    "        return chi2val, ndf\n",
    "    \n",
    "    def BakerCousinsChi2(self, model_cdf):\n",
    "        \"\"\"\n",
    "        Baker-Cousins chi2 (saturated model).\n",
    "        model_cdf is the cdf of the model\n",
    "        \"\"\"\n",
    "        nbins = len(self.data)\n",
    "        chi2val = 0\n",
    "        ndf = 0\n",
    "        for i in range(nbins):\n",
    "            d = self.data[i]\n",
    "            \n",
    "            # model prediction in that bin:\n",
    "            # integral of the pdf in the bin, i.e. difference of the cdf at the bin edges\n",
    "            p = model_cdf(bins[i+1]) - model_cdf(bins[i])\n",
    "            \n",
    "            # implement chi2 here (careful with empty bins!)\n",
    "            chi2val = ... #TODO write here\n",
    "        \n",
    "        return chi2val, ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 to pvalue\n",
    "def chi2prob(chi2val,ndf):\n",
    "    return 1 - stats.chi2.cdf(chi2val, ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters\n",
    "Nbins = 20\n",
    "xmin = -3\n",
    "xmax = 3\n",
    "Nevts = 100\n",
    "\n",
    "# true values of the parameters\n",
    "mean0 = 0.0\n",
    "sigma0 = 1.0\n",
    "\n",
    "# derived quantities\n",
    "bins = np.linspace(xmin, xmax, Nbins)\n",
    "bin_width = bins[1]-bins[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate example data\n",
    "unbinned_data = np.random.normal(mean0, sigma0, Nevts)\n",
    "\n",
    "# turn it into a histogram\n",
    "n, bins, p = plt.hist(unbinned_data, bins=bins, label='Data')\n",
    "testhist = myhist(n, bins)\n",
    "\n",
    "# estimate the parameters from the data\n",
    "mean_data = np.mean(unbinned_data)\n",
    "sigma_data = np.std(unbinned_data, ddof=1)\n",
    "\n",
    "# for plotting the pdf\n",
    "xx = np.linspace(xmin, xmax, 1000)\n",
    "# the Nevts and bin_width factors are there to properly normalise the pdf together with the histogram\n",
    "yy0 = stats.norm.pdf(xx, mean0, sigma0) * Nevts * bin_width\n",
    "yy_fit = stats.norm.pdf(xx, mean_data, sigma_data) * Nevts * bin_width\n",
    "\n",
    "# draw it, with the pdf with true or fitted parameters\n",
    "plt.plot(xx, yy0, label='Truth')\n",
    "plt.plot(xx, yy_fit, label='Estimated')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(testhist.tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ntoys=1000\n",
    "\n",
    "# arrays to hold the values\n",
    "# chi2s using true values of the parameters\n",
    "chi2s0_U, chi2s0_N, chi2s0_P, chi2s0_BC = [], [], [], []\n",
    "pvals0_U, pvals0_N, pvals0_P, pvals0_BC = [], [], [], []\n",
    "# chi2s using estimated values of the parameters\n",
    "chi2s_U, chi2s_N, chi2s_P, chi2s_BC = [], [], [], []\n",
    "pvals_U, pvals_N, pvals_P, pvals_BC = [], [], [], []\n",
    "\n",
    "# define the model cdf with true values of the parameters\n",
    "# the Nevts factor is there for normalisation\n",
    "model0_cdf = lambda x: stats.norm.cdf(x, mean0, sigma0) * Nevts\n",
    "\n",
    "for i in range(0,Ntoys):\n",
    "    toy_data = ... #TODO write here (use np.random.normal)\n",
    "    \n",
    "    # turn it into a histogram\n",
    "    n, bins = np.histogram(toy_data, bins)\n",
    "    toy_hist = myhist(n, bins)\n",
    "    \n",
    "    # compute the chi2s and p-values with the true values of the parameters\n",
    "    # unbinned\n",
    "    chi2val = ... #TODO write here\n",
    "    chi2s0_U.append(chi2val)\n",
    "    pvals0_U.append(chi2prob(chi2val, ...)) # TODO replace the ... with the proper ndf\n",
    "    \n",
    "    # Pearson\n",
    "    chi2val, ndf = toy_hist.PearsonChi2(model0_cdf)\n",
    "    chi2s0_P.append(chi2val)\n",
    "    pvals0_P.append(chi2prob(chi2val, ...))\n",
    "    \n",
    "    # Neyman\n",
    "    chi2val, ndf = ... # TODO write here (similar to Pearson chi2)\n",
    "    chi2s0_N.append(chi2val)\n",
    "    pvals0_N.append(chi2prob(chi2val, ...)) # TODO replace the ... with the proper ndf\n",
    "    \n",
    "    # Baker-Cousins\n",
    "    chi2val, ndf = ... # TODO write here (similar to Pearson chi2)\n",
    "    chi2s0_BC.append(chi2val)\n",
    "    pvals0_BC.append(chi2prob(chi2val, ...)) # TODO replace the ... with the proper ndf\n",
    "    \n",
    "    # now with the estimated values\n",
    "    mean_toy = np.mean(toy_data)\n",
    "    sigma_toy = np.std(toy_data, ddof=1)\n",
    "    model_toy_cdf = lambda x: stats.norm.cdf(x, mean_toy, sigma_toy) * Nevts\n",
    "    \n",
    "    chi2val = ... #TODO write here\n",
    "    chi2s_U.append(chi2val)\n",
    "    pvals_U.append(chi2prob(chi2val, ...)) # TODO replace the ... with the proper ndf\n",
    "\n",
    "    chi2val, ndf = ... #TODO write here\n",
    "    chi2s_P.append(chi2val)\n",
    "    pvals_P.append(chi2prob(chi2val, ...)) # TODO replace the ... with the proper ndf\n",
    "    \n",
    "    chi2val, ndf = ... #TODO write here\n",
    "    chi2s_N.append(chi2val)\n",
    "    pvals_N.append(chi2prob(chi2val, ...)) # TODO replace the ... with the proper ndf\n",
    "    \n",
    "    chi2val, ndf = ... #TODO write here\n",
    "    chi2s_BC.append(chi2val)\n",
    "    pvals_BC.append(chi2prob(chi2val, ...)) # TODO replace the ... with the proper ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "def plot_chi2(chi2s0, pvals0, chi2s, pvals, nobs, title):\n",
    "    \"\"\"\n",
    "    Plot thie chi2 and p-values and compare them with true or estimated parameters\n",
    "    \"\"\"\n",
    "    chi2min, chi2max = 0, 60\n",
    "    xchi2 = np.linspace(chi2min, chi2max, 100)\n",
    "    ychi2_pre = stats.chi2.pdf(xchi2, nobs)\n",
    "    ychi2_post = stats.chi2.pdf(xchi2, nobs-2)\n",
    "    xpval = np.linspace(0,1,100)\n",
    "    ypval = np.full_like(xpval, 1)\n",
    "\n",
    "    fig, ((ax1, ax2)) = plt.subplots(1,2)\n",
    "\n",
    "    ax1.hist(chi2s0, np.linspace(chi2min, chi2max, 20), color='r', label='true params', density=True, alpha=0.7)\n",
    "    ax1.hist(chi2s, np.linspace(chi2min, chi2max, 20), color='b',label='est. params', density=True, alpha=0.7)\n",
    "    ax1.plot(xchi2, ychi2_pre, color='r')\n",
    "    ax1.plot(xchi2, ychi2_post, color='b')\n",
    "    ax1.set_xlabel(r'$\\chi^2$')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.hist(pvals0, np.linspace(0, 1, 20), color='r', label='true params', density=True, alpha=0.7)\n",
    "    ax2.hist(pvals, np.linspace(0, 1, 20), color='b',label='est. params', density=True, alpha=0.7)\n",
    "    ax2.plot(xpval, ypval)\n",
    "    ax2.set_xlabel('p-value')\n",
    "    ax2.legend()\n",
    "    \n",
    "    print(title)\n",
    "    print(\"mean p-value with true parameters:\", np.mean(pvals0))\n",
    "    print(\"mean p-value with estimated parameters:\", np.mean(pvals))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubinned\n",
    "plot_chi2(chi2s0_U, pvals0_U, chi2s_U, pvals_U, Nevts, 'Unbinned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson\n",
    "plot_chi2(chi2s0_P, pvals0_P, chi2s_P, pvals_P, Nbins, 'Pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neyman\n",
    "plot_chi2(chi2s0_N, pvals0_N, chi2s_N, pvals_N, Nbins, 'Neyman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baker-Cousins\n",
    "plot_chi2(chi2s0_BC, pvals0_BC, chi2s_BC, pvals_BC, Nbins, 'Baker-Cousins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
